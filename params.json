{"name":"Raytracer","tagline":"Can AI find a way to project a 3D image?","body":"# Overview\r\nUsing ray tracing and artificial intelligence to make floating, 3D images\r\n\r\n(For those not in our AI class: \"Ray tracers in Matlab and Python\", [coming soon])\r\n\r\n## Holograms vs. 3D images\r\nA hologram is a photograph you can see from several angles. When illuminated correctly, you can move to a new position and see the image from a different angle. 3D images include holographic sheets, but they also include things like an image floating in fog or Star War's \"Help me Obi Wan\" scene.  The goal of this project is to create a device that will create similar, animated 3D images.\r\n\r\nToday, there are a lot of ways to create 3D images, like [holographic plates](https://en.wikipedia.org/wiki/Holography), [3D Glasses](http://science.howstuffworks.com/3-d-glasses.htm), [Heads up displays](https://www.oculus.com/en-us/), [spinning mirrors](https://www.youtube.com/watch?v=FF1vFTQOWN4), [fog projections](http://makezine.com/2014/04/18/fog-projection-combined-with-gestural-interface-to-create-hologram-touchscreen/), and [laser shows](http://www.pocket-lint.com/news/131622-holograms-are-finally-here-plasma-lasers-used-to-create-images-in-mid-air).  There are also other interesting low tech optical illusions out there, like [Pepper's Ghost](https://www.youtube.com/watch?v=TcqyoYfHIFM), and [mirascopes](https://www.youtube.com/watch?v=8m2No1NGZVc \"Mirascope on Water\").\r\n# Concept\r\nMy idea is based on a mirascope.\r\n[![Mirascope](https://img.youtube.com/vi/j0jtxXfxx3E/0.jpg)](https://www.youtube.com/watch?v=j0jtxXfxx3E \"Here Little Piggy\")\r\n\r\nTo see how they work, click [here](https://www.youtube.com/watch?v=33IvhNsiPb4)!\r\n\r\nI want to replace the top mirror and the object with an LED screen--allowing for animated, interactive objects. The problem?  A real mirascope reflects several different rays of light (different angles, different colors) off of one point in the upper mirror. An LED screen has one pixel producing one color at any given point.  This means we'll have to approximate the correct image, mapping the most important parts of the 3D image to position and direction information on our 2D screen.  How do we determine the best mapping? *Enter artificial intelligence*.\r\n\r\n![Concept Drawing](https://raw.githubusercontent.com/brywalker1/RayTracer/master/AI%20stuff/Concept%20Drawing.jpg)\r\n\r\n# Hill Climbing AI\r\nOne of the most basic forms of artificial intelligence is called hill climbing. In hill climbing, AI finds a solution, scores it according to some metric, and then tries to find a better one.  After doing this for several days, weeks, or even months, it finds a 'good' solution (although not necessarily the 'best' solution) based on the scoring metric used.\r\n\r\n# Scoring\r\nThere are two important 'scores' for creating 3D images: \r\n* Each point in your image needs to be visible from several directions\r\n* There need to be a lot of points to make an image\r\n\r\nThe tool used for scoring a particular mapping is a set of unit vectors, distributed around a sphere. We will call them sphere vectors.  They represent possible viewing angles for a given point in space.\r\n\r\nScoring Algorithm:\r\n* For each point in space, determine which light rays passed through it\r\n   * For each sphere vector\r\n      * Take the dot product of each light ray at the point in space with the sphere vector\r\n      * Save the largest resulting value.\r\n      * This value represents the light ray closest to the sphere vector's direction\r\n* Sum the largest results for each sphere vector at each point in space.  This is your **score.**\r\n\r\nThis scoring metric has three important results:\r\n\r\n1. As light rays move to cover more viewing angles, your score increases \r\n2. As light rays move to cover more points, your score increases\r\n3. If two rays travel in the same direction from the same point, your score does **NOT** increase.  Because the algorithm stored only the highest value, the second ray is not scored and can be used at a different point.\r\n\r\n# Results\r\nHere is a display of what I have running so far:  This screen replaces the upper screen of the mirascope, and the colors represent directions the LEDs are pointing. More red means the LEDs are pointing toward the right. More green means they are pointing toward the bottom of the screen, and more blue means they are pointing directly into the screen, straight toward the mirror (you'll have to imagine the mirror.)\r\n\r\n[![LEDscreen](https://img.youtube.com/vi/DnGfxbo61G0/0.jpg)](https://www.youtube.com/watch?v=DnGfxbo61G0 \"LED screen\")","google":"UA-70289165-1","note":"Don't delete this file! It's used internally to help with page regeneration."}